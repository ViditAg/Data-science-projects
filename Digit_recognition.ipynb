{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda2\\envs\\tensorflow_env\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Digit recognition using deep learning: Feed-forward Multi-layer perceptron\n",
    "#Problem: https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits\n",
    "# Identify the digit in given images. We have total 70,000 images, out of which 49,000 are part of train \n",
    "#images with the label of digit and rest 21,000 images are unlabeled (known as test images).\n",
    "#import matplotlib as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random seed\n",
    "seed=128\n",
    "rng=np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir=os.path.abspath('..\\..')\n",
    "os.path.exists(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(os.path.join(root_dir,'Jupyter\\Digit_recognition-deep learning\\Train','train.csv'))\n",
    "test=pd.read_csv('Test.csv')\n",
    "Sample_submission=pd.read_csv('Sample_Submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename\n",
       "0  49000.png\n",
       "1  49001.png\n",
       "2  49002.png\n",
       "3  49003.png\n",
       "4  49004.png"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49000 entries, 0 to 48999\n",
      "Data columns (total 2 columns):\n",
      "filename    49000 non-null object\n",
      "label       49000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 765.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21000 entries, 0 to 20999\n",
      "Data columns (total 1 columns):\n",
      "filename    21000 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 164.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a random input file\n",
    "img_name=rng.choice(train.filename)\n",
    "filepath=os.path.join(root_dir,'Jupyter\\Digit_recognition-deep learning\\Train','Images','train',img_name)\n",
    "img=imread(filepath)\n",
    "pylab.imshow(img,cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating numerical representations of train and test data\n",
    "temp=[]\n",
    "for img_name in train.filename:\n",
    "    imagepath=os.path.join(root_dir,'Jupyter\\Digit_recognition-deep learning\\Train','Images','train',img_name)\n",
    "    img=imread(imagepath)\n",
    "    img=img.astype('float32')\n",
    "    temp.append(img)\n",
    "train_x=np.stack(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[]\n",
    "for img_name in test.filename:\n",
    "    imagepath=os.path.join(root_dir,'Jupyter\\Digit_recognition-deep learning\\Train','Images','test',img_name)\n",
    "    img=imread(imagepath)\n",
    "    img=img.astype('float32')\n",
    "    temp.append(img)\n",
    "test_x=np.stack(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting training data in training+validation data in 70:30 ratio\n",
    "split_size=int(train_x.shape[0]*0.7)\n",
    "train_x, val_x= train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y= train.label.values[:split_size], train.label.values[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label to one-hot vectors\n",
    "def dense_to_one_hot(labels_dense,num_classes=10):\n",
    "    num_labels=labels_dense.shape[0]\n",
    "    index_offset=np.arange(num_labels)*num_classes\n",
    "    label_one_hot=np.zeros((num_labels,num_classes))\n",
    "    label_one_hot.flat[index_offset+labels_dense.ravel()]=1\n",
    "    return label_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize by max value\n",
    "def preproc(unclean_batch_x):\n",
    "    return unclean_batch_x/unclean_batch_x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random samples batch\n",
    "def batch_creator(batch_size,dataset_length,dataset_name):\n",
    "    batch_mask=rng.choice(dataset_length,batch_size)\n",
    "    batch_x=eval(dataset_name+'_x')[[batch_mask]].reshape(-1,input_num_units)\n",
    "    batch_x=preproc(batch_x)\n",
    "    if dataset_name=='train':\n",
    "        batch_y=eval(dataset_name).ix[batch_mask,'label'].values\n",
    "        batch_y=dense_to_one_hot(batch_y)\n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the variables\n",
    "input_num_units=28*28*4\n",
    "hidden_num_units=500\n",
    "output_num_units=10\n",
    "\n",
    "#define placeholders\n",
    "x=tf.placeholder(tf.float32,[None,input_num_units])\n",
    "y=tf.placeholder(tf.float32,[None,output_num_units])\n",
    "\n",
    "epochs=5\n",
    "batch_size=128\n",
    "learning_rate=0.01\n",
    "\n",
    "weights={\n",
    "    'hidden':tf.Variable(tf.random_normal([input_num_units,hidden_num_units],seed=seed)),\n",
    "    'output':tf.Variable(tf.random_normal([hidden_num_units,output_num_units],seed=seed))\n",
    "}\n",
    "bias={\n",
    "    'hidden':tf.Variable(tf.random_normal([hidden_num_units],seed=seed)),\n",
    "    'output':tf.Variable(tf.random_normal([output_num_units],seed=seed))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the neural network computational graph\n",
    "hidden_layer=tf.add(tf.matmul(x,weights['hidden']),bias['hidden'])\n",
    "hidden_layer=tf.nn.relu(hidden_layer)\n",
    "\n",
    "output_layer=tf.add(tf.matmul(hidden_layer,weights['output']),bias['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function: Cross entropy loss using softmax\n",
    "Cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output_layer,labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization function: Adam optimizer for gradient descent algorithm\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the variables\n",
    "init=tf.initializers.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda2\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Miniconda2\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Cost: 33.71544515961754\n",
      "Epoch: 2 Cost: 7.1184019811490495\n",
      "Epoch: 3 Cost: 4.033201471439206\n",
      "Epoch: 4 Cost: 2.5772221841608247\n",
      "Epoch: 5 Cost: 1.9698961166426046\n",
      "Training Complete.\n",
      "Accuracy on Validation dataset: 0.9440136\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #Training the neural network\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost=0\n",
    "        total_batch=int(train.shape[0]/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y=batch_creator(batch_size,train_x.shape[0],'train')\n",
    "            _, c=sess.run([optimizer, Cost], feed_dict= {x: batch_x, y: batch_y})\n",
    "            avg_cost+=c/total_batch\n",
    "        print ('Epoch:',epoch+1,'Cost:',avg_cost)\n",
    "    print('Training Complete.')\n",
    "    #Finding prediction on validation set\n",
    "    pred_temp=tf.equal(tf.argmax(output_layer,1),tf.argmax(y,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(pred_temp,\"float\"))\n",
    "    print('Accuracy on Validation dataset:',accuracy.eval({x: val_x.reshape(-1,input_num_units),y: dense_to_one_hot(val_y)}))\n",
    "    predict=tf.argmax(output_layer,1)\n",
    "    pred=predict.eval({x:test_x.reshape(-1,input_num_units)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking prdiction on one test case\n",
    "img_name=rng.choice(test.filename)\n",
    "filepath=os.path.join(root_dir,'Jupyter\\Digit_recognition-deep learning\\Train','Images','test',img_name)\n",
    "img=imread(filepath)\n",
    "test_index=int(img_name.split('.')[0])-49000\n",
    "print('Prediction is:', pred[test_index])\n",
    "pylab.imshow(img,cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=test\n",
    "submission['label']=pred\n",
    "submission\n",
    "submission.to_csv('Submission.csv',index=False)\n",
    "#Final score: 0.945"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
